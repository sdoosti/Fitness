{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "\n",
    "EMBED_PATH = \"E:/\"\n",
    "DATA_PATH = \"C:/Users/doosti/Dropbox (Chapman)/Research/Research Projects/Fitness/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(221979, 11)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "with open(os.path.join(DATA_PATH,\"processed_comments_102423.txt\"),\"r\", encoding=\"utf-8\") as f:\n",
    "    processed_docs = f.readlines()\n",
    "comments = pd.read_csv(os.path.join(DATA_PATH, \"merged_comments.csv\"))\n",
    "comments = comments[comments.comment_text.notnull()].copy()\n",
    "comments['processed_text'] = [re.sub(\"\\d+\", \"\", x.strip())for x in processed_docs]\n",
    "comments['length'] = comments.processed_text.apply(lambda x: len(x.split(',')))\n",
    "comments['include'] = comments.length > 10\n",
    "comments = comments[comments.include].copy()\n",
    "print(comments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(221979, 768)\n"
     ]
    }
   ],
   "source": [
    "# Load the embeddings\n",
    "#embed_file = \"bert_embeddings_221979docs_sentence_lowercase_071123.npy\"\n",
    "#embed_file = \"bert_embeddings_221979docs_sentence_original_071123.npy\"\n",
    "embed_file = \"bert_embeddings_221979docs_sentence_tokens_071123.npy\"\n",
    "\n",
    "embeddings = np.load(os.path.join(EMBED_PATH, embed_file), allow_pickle=True)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\doosti\\.conda\\envs\\ctm\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(221979,)\n"
     ]
    }
   ],
   "source": [
    "# KMeans clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Fit the model\n",
    "kmeans = KMeans(n_clusters=20, random_state=42).fit(embeddings)\n",
    "labels = kmeans.labels_\n",
    "print(labels.shape)\n",
    "\n",
    "# Get the silhouette score\n",
    "silhouette_score(embeddings, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the clusters\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Fit the model\n",
    "pca.fit(embeddings)\n",
    "X = pca.transform(embeddings)\n",
    "print(X.shape)\n",
    "\n",
    "# Plot the clusters\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(X[:,0], X[:,1], c=labels, cmap='tab20')\n",
    "plt.show()\n",
    "\n",
    "# Get the top words in each cluster\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Get the top words in each cluster\n",
    "def get_top_words(X, labels, n=10):\n",
    "    # Get the top words in each cluster\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(X)\n",
    "    tfidf = TfidfTransformer()\n",
    "    X = tfidf.fit_transform(X)\n",
    "    words = vectorizer.get_feature_names()\n",
    "    clusters = np.unique(labels)\n",
    "    top_words = []\n",
    "    for cluster in clusters:\n",
    "        # Get the indices of the cluster\n",
    "        idx = np.where(labels == cluster)[0]\n",
    "        # Get the words in the cluster\n",
    "        cluster_words = X[idx,:].sum(axis=0).A1\n",
    "        # Get the top words in the cluster\n",
    "        top_idx = np.argsort(cluster_words)[::-1][:n]\n",
    "        top_words.append([words[i] for i in top_idx])\n",
    "    return top_words\n",
    "\n",
    "top_words = get_top_words(comments.processed_text, labels, n=10)\n",
    "for i, words in enumerate(top_words):\n",
    "    print(\"Cluster {}: {}\".format(i, words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "X = tsne.fit_transform(embeddings)\n",
    "print(X.shape)\n",
    "\n",
    "# Plot the clusters\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(X[:,0], X[:,1], c=labels, cmap='tab20')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'person,read,comment,wish,great,success,health,love,happiness,lot,positive,energy'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.processed_text.iloc[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
